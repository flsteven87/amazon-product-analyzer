# ğŸš€ Amazon Product Analyzer

AI-powered Amazon product analysis and optimization platform using LangGraph Multi-Agent architecture.

## ğŸ“‹ Project Overview

Amazon Product Analyzer æ˜¯ä¸€å€‹æ•´åˆ LangGraph Multi-Agent æ¶æ§‹çš„å…¨ç«¯æ‡‰ç”¨ï¼Œç”¨æ–¼åˆ†æ Amazon ç”¢å“ä¸¦æä¾›å„ªåŒ–å»ºè­°ã€‚ç³»çµ±æ¡ç”¨ hierarchical multi-agent design patternï¼Œæ”¯æ´å³æ™‚ workflow visualization èˆ‡ comprehensive product analysisã€‚

## ğŸ—ï¸ Architecture

### Multi-Agent System Design

```
ProductAnalysisSystem (Supervisor Agent)
â”œâ”€â”€ DataCollectorAgent     # ç”¢å“èˆ‡ç«¶å“æ•¸æ“šæ”¶é›† specialist
â”œâ”€â”€ MarketAnalyzerAgent    # ç«¶çˆ­åˆ†æèˆ‡å¸‚å ´å®šä½ specialist
â””â”€â”€ OptimizationAdvisorAgent # ç”¢å“å„ªåŒ–å»ºè­° specialist
```

### Technology Stack

**Backend:**
- Python 3.9+ with FastAPI
- LangGraph for Multi-Agent orchestration
- PostgreSQL + Redis for data storage
- Playwright for web scraping
- Pydantic for data validation

**Frontend:**
- Next.js 14+ with TypeScript
- Tailwind CSS for styling
- WebSocket for real-time communication

**AI/Data:**
- OpenAI API & Claude API
- LangChain for AI toolchain
- Pandas/NumPy for data processing

## ğŸ“‚ Project Structure

```
amazon-product-analyzer/
â”œâ”€â”€ backend/                    # FastAPI å¾Œç«¯æœå‹™
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/               # FastAPI Routes
â”‚   â”‚   â”‚   â””â”€â”€ v1/           # API v1 endpoints
â”‚   â”‚   â”‚       â”œâ”€â”€ api.py    # Main API router
â”‚   â”‚   â”‚       â”œâ”€â”€ auth.py   # Authentication endpoints
â”‚   â”‚   â”‚       â””â”€â”€ chatbot.py # LangGraph chatbot endpoints
â”‚   â”‚   â”œâ”€â”€ core/              # æ ¸å¿ƒæœå‹™é…ç½®
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py     # Application configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ logging.py    # Structured logging setup
â”‚   â”‚   â”‚   â”œâ”€â”€ metrics.py    # Prometheus metrics
â”‚   â”‚   â”‚   â”œâ”€â”€ middleware.py # FastAPI middleware
â”‚   â”‚   â”‚   â”œâ”€â”€ limiter.py    # Rate limiting
â”‚   â”‚   â”‚   â”œâ”€â”€ langgraph/    # LangGraph agent implementation
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ graph.py  # Main LangGraph agent
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tools/    # LangGraph tools
â”‚   â”‚   â”‚   â””â”€â”€ prompts/      # System prompts
â”‚   â”‚   â”œâ”€â”€ models/            # SQLModel/SQLAlchemy Models
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py       # Base model classes
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py   # Database configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py       # User model
â”‚   â”‚   â”‚   â”œâ”€â”€ session.py    # Session model
â”‚   â”‚   â”‚   â””â”€â”€ thread.py     # Thread model
â”‚   â”‚   â”œâ”€â”€ schemas/           # Pydantic schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py       # Authentication schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py       # Chat request/response schemas
â”‚   â”‚   â”‚   â””â”€â”€ graph.py      # LangGraph state schemas
â”‚   â”‚   â”œâ”€â”€ services/          # Business logic services
â”‚   â”‚   â”‚   â””â”€â”€ database.py   # Database service layer
â”‚   â”‚   â”œâ”€â”€ utils/             # å·¥å…·å‡½æ•¸
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py       # JWT token utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ graph.py      # LangGraph utilities
â”‚   â”‚   â”‚   â””â”€â”€ sanitization.py # Input sanitization
â”‚   â”‚   â””â”€â”€ main.py           # FastAPI App Entry
â”‚   â”œâ”€â”€ evals/                # LLM evaluation framework
â”‚   â”‚   â”œâ”€â”€ evaluator.py      # Main evaluation engine
â”‚   â”‚   â”œâ”€â”€ metrics/          # Evaluation metrics
â”‚   â”‚   â””â”€â”€ schemas.py        # Evaluation schemas
â”‚   â”œâ”€â”€ grafana/              # Grafana dashboards
â”‚   â”œâ”€â”€ prometheus/           # Prometheus configuration
â”‚   â”œâ”€â”€ scripts/              # Deployment and utility scripts
â”‚   â”œâ”€â”€ logs/                 # Application logs
â”‚   â”œâ”€â”€ schema.sql            # Database schema
â”‚   â”œâ”€â”€ Dockerfile            # Container configuration
â”‚   â”œâ”€â”€ docker-compose.yml    # Multi-container setup
â”‚   â”œâ”€â”€ Makefile              # Development commands
â”‚   â”œâ”€â”€ pyproject.toml        # uv å°ˆæ¡ˆé…ç½®
â”‚   â””â”€â”€ uv.lock              # uv ä¾è³´é–å®šæª”æ¡ˆ
â”œâ”€â”€ frontend/                 # Streamlit æ¸¬è©¦å‰ç«¯ (å·²å¯¦ç¾)
â”œâ”€â”€ PLANNING.md              # å°ˆæ¡ˆæ¶æ§‹è¦åŠƒ
â”œâ”€â”€ SPEC.md                  # å°ˆæ¡ˆè¦æ ¼èªªæ˜
â”œâ”€â”€ TASK.md                  # ä»»å‹™è¿½è¹¤
â””â”€â”€ README.md               # æ­¤æ–‡æª”
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Node.js 18+ (for frontend)
- PostgreSQL
- Redis
- uv (Python package manager)

### Backend Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd amazon-product-analyzer
   ```

2. **Backend development**
   ```bash
   cd backend
   
   # Install dependencies with uv
   uv sync
   
   # Activate virtual environment
   source .venv/bin/activate
   
   # Or run with uv directly
   uv run python app/main.py
   ```

3. **Environment configuration**
   ```bash
   # Copy environment template
   cp .env.example .env
   
   # Edit environment variables
   # Add your OpenAI API key, database URLs, etc.
   ```

4. **Database setup**
   ```bash
   # Run database migrations
   uv run alembic upgrade head
   ```

5. **Start the backend server**
   ```bash
   # Development mode
   uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
   
   # Or using the main script
   uv run python app/main.py
   ```

### API Documentation

Once the backend is running, visit:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health

## ğŸ”§ Development

### Code Quality Tools

```bash
# Code formatting
uv run black app/
uv run isort app/

# Type checking
uv run mypy app/

# Linting
uv run flake8 app/

# Testing
uv run pytest
```

### Project Management

- **Planning**: See `PLANNING.md` for architectural decisions
- **Tasks**: See `TASK.md` for development progress
- **Specifications**: See `SPEC.md` for detailed requirements

## ğŸ§ª Testing

```bash
# Run all tests
uv run pytest

# Run with coverage
uv run pytest --cov=app --cov-report=html

# Run specific test categories
uv run pytest tests/unit/
uv run pytest tests/integration/
uv run pytest tests/e2e/
```

## ğŸ“Š Core Features

### 1. Product Analysis Workflow
- Amazon product data extraction
- Competitor discovery and analysis
- Review sentiment analysis
- Market positioning insights

### 2. Multi-Agent Coordination
- Supervisor agent orchestration
- Specialized agent coordination
- Real-time progress tracking
- Error handling and recovery

### 3. Real-time Visualization
- WebSocket-based progress updates
- Dynamic result streaming
- Interactive dashboard
- Comprehensive reporting

## ğŸ”‘ API Key Configuration

You'll need API keys for:
- **OpenAI API**: For GPT models
- **Claude API (Anthropic)**: For Claude models

Add these to your `.env` file:
```env
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_claude_api_key_here
```

## ğŸ³ Docker Deployment

```bash
# Build and run with docker-compose
docker-compose up --build

# Development mode
docker-compose -f docker-compose.dev.yml up
```

## ğŸ“ License

This project is licensed under the MIT License.

## ğŸ‘¥ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Ensure all tests pass
6. Submit a pull request

## ğŸ“ Support

For questions and support, please refer to:
- Project documentation in `PLANNING.md`
- Task tracking in `TASK.md`
- Technical specifications in `SPEC.md`

---

**Built with â¤ï¸ using LangGraph, FastAPI, and Next.js** 