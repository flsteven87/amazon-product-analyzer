# ğŸš€ Amazon Product Analyzer

AI-powered Amazon product analysis and optimization platform using LangGraph Multi-Agent architecture.

## ğŸ“‹ Project Overview

Amazon Product Analyzer æ˜¯ä¸€å€‹æ•´åˆ LangGraph Multi-Agent æ¶æ§‹çš„å…¨ç«¯æ‡‰ç”¨ï¼Œç”¨æ–¼åˆ†æ Amazon ç”¢å“ä¸¦æä¾›å„ªåŒ–å»ºè­°ã€‚ç³»çµ±æ¡ç”¨ hierarchical multi-agent design patternï¼Œæ”¯æ´å³æ™‚ workflow visualization èˆ‡ comprehensive product analysisã€‚

## ğŸ—ï¸ Architecture

### Multi-Agent System Design

```
ProductAnalysisSystem (Supervisor Agent)
â”œâ”€â”€ DataCollectorAgent     # ç”¢å“èˆ‡ç«¶å“æ•¸æ“šæ”¶é›† specialist
â”œâ”€â”€ MarketAnalyzerAgent    # ç«¶çˆ­åˆ†æèˆ‡å¸‚å ´å®šä½ specialist
â””â”€â”€ OptimizationAdvisorAgent # ç”¢å“å„ªåŒ–å»ºè­° specialist
```

### Technology Stack

**Backend:**
- Python 3.9+ with FastAPI
- LangGraph for Multi-Agent orchestration
- Supabase PostgreSQL for data storage
- BeautifulSoup & HTTPX for web scraping
- Pydantic for data validation
- Streamlit for testing interface

**Frontend:**
- Next.js 14+ with TypeScript
- Tailwind CSS for styling
- React Query for state management
- Socket.io for real-time communication

**AI/Data:**
- OpenAI API (GPT models)
- LangChain for AI toolchain
- Pandas for data processing

## ğŸ“‚ Project Structure

```
amazon-product-analyzer/
â”œâ”€â”€ backend/                    # FastAPI å¾Œç«¯æœå‹™
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/               # FastAPI Routes
â”‚   â”‚   â”‚   â””â”€â”€ v1/           # API v1 endpoints
â”‚   â”‚   â”‚       â”œâ”€â”€ api.py    # Main API router
â”‚   â”‚   â”‚       â””â”€â”€ product_analysis.py # Product analysis endpoints
â”‚   â”‚   â”œâ”€â”€ core/              # æ ¸å¿ƒæœå‹™é…ç½®
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py     # Application configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ logging.py    # Structured logging setup
â”‚   â”‚   â”‚   â”œâ”€â”€ agents/       # Multi-Agent implementation
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ base.py   # Base agent class
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ supervisor.py # Supervisor agent
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ data_collector.py # Data collection agent
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ market_analyzer.py # Market analysis agent
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ optimization_advisor.py # Optimization agent
â”‚   â”‚   â”‚   â”œâ”€â”€ graph/        # LangGraph workflow
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ state.py  # Graph state definition
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ workflow.py # Main workflow implementation
â”‚   â”‚   â”‚   â””â”€â”€ tools/        # Agent tools
â”‚   â”‚   â”‚       â”œâ”€â”€ scraper.py # Web scraping tools
â”‚   â”‚   â”‚       â”œâ”€â”€ product_parser.py # Product data parser
â”‚   â”‚   â”‚       â””â”€â”€ competitor_extractor.py # Competitor discovery
â”‚   â”‚   â”œâ”€â”€ models/           # SQLModel/SQLAlchemy Models
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py       # Base model classes
â”‚   â”‚   â”‚   â””â”€â”€ analysis.py   # Analysis models
â”‚   â”‚   â”œâ”€â”€ schemas/          # Pydantic schemas
â”‚   â”‚   â”‚   â””â”€â”€ analysis.py   # Analysis request/response schemas
â”‚   â”‚   â”œâ”€â”€ services/         # Business logic services
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py   # Database service layer
â”‚   â”‚   â”‚   â””â”€â”€ analysis_service.py # Analysis orchestration
â”‚   â”‚   â”œâ”€â”€ utils/            # å·¥å…·å‡½æ•¸
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py   # Utility functions
â”‚   â”‚   â”œâ”€â”€ cli.py           # Command line interface
â”‚   â”‚   â””â”€â”€ main.py          # FastAPI App Entry
â”‚   â”œâ”€â”€ streamlit_app.py     # Streamlit testing interface
â”‚   â”œâ”€â”€ evals/               # LLM evaluation framework
â”‚   â”‚   â”œâ”€â”€ evaluator.py     # Main evaluation engine
â”‚   â”‚   â”œâ”€â”€ metrics/         # Evaluation metrics
â”‚   â”‚   â””â”€â”€ schemas.py       # Evaluation schemas
â”‚   â”œâ”€â”€ grafana/             # Grafana dashboards
â”‚   â”œâ”€â”€ prometheus/          # Prometheus configuration
â”‚   â”œâ”€â”€ scripts/             # Deployment and utility scripts
â”‚   â”œâ”€â”€ logs/                # Application logs
â”‚   â”œâ”€â”€ Dockerfile           # Container configuration
â”‚   â”œâ”€â”€ docker-compose.yml   # Multi-container setup
â”‚   â”œâ”€â”€ Makefile             # Development commands
â”‚   â”œâ”€â”€ pyproject.toml       # uv å°ˆæ¡ˆé…ç½®
â”‚   â””â”€â”€ uv.lock             # uv ä¾è³´é–å®šæª”æ¡ˆ
â”œâ”€â”€ frontend/                # Next.js å‰ç«¯æ‡‰ç”¨
â”‚   â”œâ”€â”€ app/                 # Next.js App Router
â”‚   â”‚   â”œâ”€â”€ layout.tsx       # Root layout
â”‚   â”‚   â”œâ”€â”€ page.tsx         # Homepage
â”‚   â”‚   â””â”€â”€ analysis/        # Analysis pages
â”‚   â”œâ”€â”€ components/          # React components
â”‚   â”‚   â”œâ”€â”€ analysis/        # Analysis-specific components
â”‚   â”‚   â”œâ”€â”€ layout/          # Layout components
â”‚   â”‚   â””â”€â”€ ui/             # UI components
â”‚   â”œâ”€â”€ lib/                 # Utilities and providers
â”‚   â”œâ”€â”€ services/            # API services
â”‚   â”œâ”€â”€ types/               # TypeScript types
â”‚   â”œâ”€â”€ package.json         # Node dependencies
â”‚   â””â”€â”€ tsconfig.json        # TypeScript configuration
â””â”€â”€ README.md               # æ­¤æ–‡æª”
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Node.js 18+ (for frontend)
- PostgreSQL
- uv (Python package manager)

### Backend Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd amazon-product-analyzer
   ```

2. **Backend development**
   ```bash
   cd backend
   
   # Install dependencies with uv
   uv sync
   
   # Activate virtual environment
   source .venv/bin/activate
   
   # Or run with uv directly
   uv run python app/main.py
   ```

3. **Environment configuration**
   ```bash
   # Create environment file
   cp .env.example .env
   
   # Edit environment variables
   # Add your OpenAI API key, database URLs, etc.
   ```

4. **Database setup**
   ```bash
   # Set up PostgreSQL database
   # Update POSTGRES_URL in .env file
   
   # Run database migrations if needed
   # uv run alembic upgrade head
   ```

5. **Start the backend server**
   ```bash
   # Development mode
   uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
   
   # Or using the main script
   uv run python app/main.py
   ```

### Frontend Setup

1. **Frontend development**
   ```bash
   cd frontend
   
   # Install dependencies
   npm install
   
   # Start development server
   npm run dev
   ```

2. **Access the applications**
   - **Frontend**: http://localhost:3000
   - **Backend API**: http://localhost:8000
   - **Streamlit Testing Interface**: `uv run streamlit run streamlit_app.py`

### API Documentation

Once the backend is running, visit:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health

## ğŸ”§ Development

### Code Quality Tools

```bash
# Code formatting
uv run black app/
uv run isort app/

# Type checking
uv run mypy app/

# Linting
uv run ruff check app/

# Testing
uv run pytest
```

### Using the CLI

```bash
# Run analysis via CLI
uv run python app/cli.py analyze "https://amazon.com/dp/PRODUCT_ID"

# Check system status
uv run python app/cli.py status
```

## ğŸ§ª Testing

```bash
# Run all tests
uv run pytest

# Run with coverage
uv run pytest --cov=app --cov-report=html

# Run specific test categories
uv run pytest tests/unit/
uv run pytest tests/integration/
```

## ğŸ“Š Core Features

### 1. Product Analysis Workflow
- Amazon product data extraction using web scraping
- Competitor discovery and analysis
- Market positioning insights
- Product optimization recommendations

### 2. Multi-Agent Coordination
- Supervisor agent orchestration
- Specialized agent coordination (Data Collection, Market Analysis, Optimization)
- Real-time progress tracking
- Error handling and recovery

### 3. Multiple Interfaces
- **Next.js Frontend**: Modern web interface for production use
- **Streamlit Interface**: Testing and development interface
- **FastAPI Backend**: RESTful API for all operations
- **CLI Interface**: Command-line tool for batch operations

### 4. Real-time Features
- WebSocket-based progress updates
- Dynamic result streaming
- Task status monitoring
- Comprehensive reporting

## ğŸ”‘ API Key Configuration

You'll need API keys for:
- **OpenAI API**: For GPT models

Add these to your `.env` file:
```env
LLM_API_KEY=your_openai_api_key_here
POSTGRES_URL=postgresql://user:password@localhost:5432/dbname
```

## ğŸ³ Docker Deployment

```bash
# Build and run with docker-compose
docker-compose up --build

# Development mode
docker-compose -f docker-compose.dev.yml up
```

## ğŸ“Š Monitoring & Observability

- **Grafana Dashboards**: Performance and usage metrics
- **Prometheus**: Metrics collection
- **Structured Logging**: JSON-formatted logs with context
- **Health Checks**: System status monitoring

## ğŸ§© Development Prototype

The `developing/simple_multi_agent/` directory contains a simplified prototype implementation that demonstrates the core multi-agent concepts. This can be used for:
- Testing new agent logic
- Understanding the workflow
- Rapid prototyping

```bash
cd developing/simple_multi_agent
uv run python run_analysis.py
```

## ğŸ“ License

This project is licensed under the MIT License.

## ğŸ‘¥ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Ensure all tests pass
6. Submit a pull request

## ğŸ“ Support

For questions and support, please refer to:
- API documentation at `/docs` endpoint
- Code examples in `developing/` directory
- Test files for usage patterns

---

**Built with â¤ï¸ using LangGraph, FastAPI, and Next.js** 